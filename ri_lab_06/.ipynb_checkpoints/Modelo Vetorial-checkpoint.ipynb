{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Vetorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando-se os pacotes necessários para a atividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from math import log\n",
    "from collections import Counter\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo-se a coleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"results.csv\")\n",
    "documentos = data_frame[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Reconstruir o índice considerando o conjunto de dados que indicamos. Esses são os dados coletados por Bernardi e os estaremos usando para facilitar a correção da atividade. Se você já estiver usando esses dados não precisa reconstruir o índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando-se os índices invertidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmo \"parse\" para obter os tokens de um determinado documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pontuacao(token):\n",
    "    '''\n",
    "        Retorna-se um booleano indicando se o token passado por parâmetro é uma pontuação.\n",
    "    '''\n",
    "    lista_pontuacoes = [\",\", \".\", \"!\", \"?\", \":\", \"/\", \"#\", \"*\", \"(\", \")\", \";\", \"\"]\n",
    "    return token.strip() in lista_pontuacoes\n",
    "\n",
    "def remove_acentuacoes(token):\n",
    "    '''\n",
    "        Remove as acentuações de um token.\n",
    "    '''\n",
    "    token_unicode = unicode(token, \"utf-8\")\n",
    "    return normalize('NFKD', token_unicode).encode('ASCII','ignore')\n",
    "\n",
    "def parse(texto):\n",
    "    '''\n",
    "        Transforma o texto em uma lista de tokens, eliminando espaços vazios, acentuações e pontuações, e\n",
    "        tranforma todas as palavras em letras minúsculas.\n",
    "    '''\n",
    "    texto = re.sub(r'[,.!?:*();]', ' ', str(texto))\n",
    "    texto = re.sub(r'\\n', ' ', texto)\n",
    "    lista_texto = texto.split(' ')\n",
    "\n",
    "    tokens = []\n",
    "    for palavra in lista_texto:\n",
    "        token = palavra.lower()\n",
    "        token = token.strip()\n",
    "        token = remove_acentuacoes(token)\n",
    "\n",
    "        if(not is_pontuacao(token)):\n",
    "            tokens.append(token)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmo para obtenção dos índices invertidos com frequência (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_invertidos_com_frequencia(documentos):\n",
    "    '''\n",
    "        Obtém uma lista de índices invertidos a partir de uma lista de documentos,\n",
    "        com a frequência do índice em cada um desses documentos.\n",
    "    '''\n",
    "    indices_invertidos = {}\n",
    "    for i in range(len(documentos)):\n",
    "        doc = parse(documentos[i])\n",
    "        documento_counter = Counter(doc)\n",
    "        \n",
    "        for indice in documento_counter.keys():\n",
    "            if(len(indice) > 3):\n",
    "                if(indice in indices_invertidos):\n",
    "                    indices_invertidos[indice][i] = documento_counter[indice]\n",
    "                else:\n",
    "                    indices_invertidos[indice] = { i: documento_counter[indice] }\n",
    "    \n",
    "    return indices_invertidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Refinar o índice invertido de forma a também incluir o IDF (inverse document frequency) de cada termo do dicionário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo-se os índices com IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_invertidos_com_frequencia = get_indices_invertidos_com_frequencia(documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Implementar as seguintes versões do modelo vetorial:\n",
    "\n",
    "    1. Representação binária;\n",
    "    2. TF (lembre-se que esse modelo já está implementado);\n",
    "    3. TF-IDF;\n",
    "    4. BM25* (não usaremos Okapi já que os documentos não tem grande variação de tamanho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmos úteis para as implementações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuplas_documentos_ordenados_peso(dic_documentos):\n",
    "    '''\n",
    "        Obtém-se tuplas de documentos ordenados decrescentemente pelo peso, a partir de um dicionário\n",
    "        que tem como chave o documento, e valor o peso.\n",
    "    '''\n",
    "    documentos_tuplas = dic_documentos.items()\n",
    "    indice_peso = 1\n",
    "    documentos_tuplas.sort(key = operator.itemgetter(indice_peso), reverse=True)\n",
    "    \n",
    "    return documentos_tuplas\n",
    "\n",
    "def get_K_primeiros_ids_documentos(documentos_tuplas, k):\n",
    "    '''\n",
    "        Obtendo-se a lista de id dos k primeiros documentos, a partir de uma lista de tuplas, as quais\n",
    "        o primeiro índice é o id do documento e o segundo é o seu peso.\n",
    "    '''\n",
    "    id_documentos_ordenados = [id_documento for id_documento, peso in documentos_tuplas]\n",
    "    k_primeiros_id_documentos = id_documentos_ordenados[:k]\n",
    "    \n",
    "    return k_primeiros_id_documentos\n",
    "\n",
    "def idf(quantidade_documentos_colecao, quantidade_documentos_com_palavra):\n",
    "    '''\n",
    "        Calcula o Inverse Document Frequency (IDF).\n",
    "    '''\n",
    "    return log((quantidade_documentos_colecao + 1) / quantidade_documentos_com_palavra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação do algoritmo para a *Representação Binária*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[137, 14, 25, 167, 171, 72, 203, 215, 233, 235]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_documentos_ordem_representacao_binaria(consulta, indices_invertidos, k_primeiros_elementos):\n",
    "    '''\n",
    "        Obtém os documentos ordenados segundo a ideia de \"Representação Binária\",\n",
    "        na qual, os documentos que possuem a maior quantidade de termos da consultas\n",
    "        são os mais representativos.\n",
    "    '''\n",
    "    # Separando-se os termos da pesquisa, de forma a evitar a contagem de palavras repetidas. Por exemplo,\n",
    "    # uma consulta por \"thaynan andrey thaynan\", evitaria que eu calculasse \"thaynan\" duas vezes.\n",
    "    termos_counter = Counter(consulta)\n",
    "    \n",
    "    # Obtendo-se os documentos e seus respectivos pesos para a consulta\n",
    "    documentos_com_peso = {}\n",
    "    for termo in termos_counter.keys():\n",
    "        \n",
    "        if(termo in indices_invertidos):\n",
    "            for id_doc in indices_invertidos[termo].keys():\n",
    "                if(id_doc in documentos_com_peso):\n",
    "                    documentos_com_peso[id_doc] = documentos_com_peso[id_doc] + 1\n",
    "                else:\n",
    "                    documentos_com_peso[id_doc] = 1\n",
    "    \n",
    "    documentos_tuplas = getTuplasDocumentosOrdenadosPeso(documentos_com_peso)\n",
    "    k_primeiros_id_documentos = get_K_primeiros_ids_documentos(documentos_tuplas, k_primeiros_elementos)\n",
    "    \n",
    "    return k_primeiros_id_documentos\n",
    "    \n",
    "get_documentos_ordem_representacao_binaria([\"bolsonaro\", \"de\", \"lula\"], indices_invertidos_com_frequencia, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação do algoritmo para a *TF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[150, 165, 206, 18, 215, 41, 207, 14, 25, 224]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_documentos_ordem_TF(consulta, indices_invertidos, k_primeiros_elementos):\n",
    "    '''\n",
    "        Obtém os documentos ordenados segundo a ideia de \"Term Frequency Weighting\",\n",
    "        na qual, quanto mais o termo se repete na consulta ou no documento, mais pesos\n",
    "        ele tem.\n",
    "    '''\n",
    "    # Separando-se os termos da pesquisa, de forma a contar a repetição de cada termo,\n",
    "    # para assim utilizá-lo no cálculo do peso.\n",
    "    termos_counter = Counter(consulta)\n",
    "    \n",
    "    # Obtendo-se os documentos e seus respectivos pesos para a consulta\n",
    "    documentos_com_peso = {}\n",
    "    for termo in termos_counter.keys():\n",
    "        \n",
    "        if(termo in indices_invertidos):\n",
    "            peso_consulta_termo = termos_counter[termo]\n",
    "            \n",
    "            for id_doc in indices_invertidos[termo].keys():\n",
    "                peso_doc_termo = indices_invertidos[termo][id_doc]\n",
    "                peso_termo = peso_consulta_termo * peso_doc_termo\n",
    "                \n",
    "                if(id_doc in documentos_com_peso):\n",
    "                    documentos_com_peso[id_doc] = documentos_com_peso[id_doc] + peso_termo\n",
    "                else:\n",
    "                    documentos_com_peso[id_doc] = peso_termo\n",
    "    \n",
    "    documentos_tuplas = get_tuplas_documentos_ordenados_peso(documentos_com_peso)\n",
    "    k_primeiros_id_documentos = get_K_primeiros_ids_documentos(documentos_tuplas, k_primeiros_elementos)\n",
    "    \n",
    "    return k_primeiros_id_documentos\n",
    "    \n",
    "get_documentos_ordem_TF([\"bolsonaro\", \"de\", \"lula\"], indices_invertidos_com_frequencia, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação do algoritmo para a *TF-IDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[150, 165, 206, 18, 14, 215, 41, 207, 25, 233]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_documentos_ordem_TF_IDF(consulta, indices_invertidos, k_primeiros_elementos):\n",
    "    '''\n",
    "        Obtém os documentos ordenados segundo a ideia de \"Term Frequency Weighting\" acrescentado do IDF,\n",
    "        no qual, termos muito populares no documento são penalizados e termos pouco populares são valorizados,\n",
    "        o que evita que stop words se sobreponham a outras palavras.\n",
    "    '''\n",
    "    quantidade_documentos_colecao = len(documentos)\n",
    "    \n",
    "    # Separando-se os termos da pesquisa, de forma a contar a repetição de cada termo,\n",
    "    # para assim utilizá-lo no cálculo do peso.\n",
    "    termos_counter = Counter(consulta)\n",
    "    \n",
    "    # Obtendo-se os documentos e seus respectivos pesos para a consulta\n",
    "    documentos_com_peso = {}\n",
    "    for termo in termos_counter.keys():\n",
    "        \n",
    "        if(termo in indices_invertidos):\n",
    "            peso_consulta_termo = termos_counter[termo]\n",
    "            quantidade_documentos_com_termo = len(indices_invertidos[termo].keys())\n",
    "            \n",
    "            for id_doc in indices_invertidos[termo].keys():\n",
    "                peso_doc_termo = indices_invertidos[termo][id_doc] * idf(quantidade_documentos_colecao, quantidade_documentos_com_termo)\n",
    "                peso_termo = peso_consulta_termo * peso_doc_termo\n",
    "                \n",
    "                if(id_doc in documentos_com_peso):\n",
    "                    documentos_com_peso[id_doc] = documentos_com_peso[id_doc] + peso_termo\n",
    "                else:\n",
    "                    documentos_com_peso[id_doc] = peso_termo\n",
    "    \n",
    "    documentos_tuplas = get_tuplas_documentos_ordenados_peso(documentos_com_peso)\n",
    "    k_primeiros_id_documentos = get_K_primeiros_ids_documentos(documentos_tuplas, k_primeiros_elementos)\n",
    "    \n",
    "    return k_primeiros_id_documentos\n",
    "    \n",
    "get_documentos_ordem_TF_IDF([\"bolsonaro\", \"de\", \"lula\"], indices_invertidos_com_frequencia, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação do algoritmo para a *BM25*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 215, 150, 165, 206, 18, 233, 25, 203, 235]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_documentos_ordem_bm25(consulta, indices_invertidos, k):\n",
    "    '''\n",
    "        Obtém os documentos ordenados segundo a ideia de \"Term Frequency Weighting\" acrescentado do IDF,\n",
    "        no qual, termos muito populares no documento são penalizados e termos pouco populares são valorizados,\n",
    "        o que evita que stop words se sobreponham a outras palavras.\n",
    "    '''\n",
    "    quantidade_documentos_colecao = len(documentos)\n",
    "    \n",
    "    # Separando-se os termos da pesquisa, de forma a contar a repetição de cada termo,\n",
    "    # para assim utilizá-lo no cálculo do peso.\n",
    "    termos_counter = Counter(consulta)\n",
    "    \n",
    "    # Obtendo-se os documentos e seus respectivos pesos para a consulta\n",
    "    documentos_com_peso = {}\n",
    "    for termo in termos_counter.keys():\n",
    "        \n",
    "        if(termo in indices_invertidos):\n",
    "            peso_consulta_termo = termos_counter[termo]\n",
    "            quantidade_documentos_com_termo = len(indices_invertidos[termo].keys())\n",
    "            \n",
    "            for id_doc in indices_invertidos[termo].keys():\n",
    "                numerador_peso_doc_termo = (k + 1) * indices_invertidos[termo][id_doc] * idf(quantidade_documentos_colecao, quantidade_documentos_com_termo)\n",
    "                denominador_peso_doc_termo = indices_invertidos[termo][id_doc] + k\n",
    "                peso_doc_termo = numerador_peso_doc_termo / denominador_peso_doc_termo\n",
    "                peso_termo = peso_consulta_termo * peso_doc_termo\n",
    "                \n",
    "                if(id_doc in documentos_com_peso):\n",
    "                    documentos_com_peso[id_doc] = documentos_com_peso[id_doc] + peso_termo\n",
    "                else:\n",
    "                    documentos_com_peso[id_doc] = peso_termo\n",
    "    \n",
    "    documentos_tuplas = get_tuplas_documentos_ordenados_peso(documentos_com_peso)\n",
    "    k_primeiros_id_documentos = get_K_primeiros_ids_documentos(documentos_tuplas, k)\n",
    "    \n",
    "    return k_primeiros_id_documentos\n",
    "    \n",
    "get_documentos_ordem_bm25([\"bolsonaro\", \"de\", \"lula\"], indices_invertidos_com_frequencia, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Execute os algoritmos separadamente em 3 consultas de sua escolha e retorne os top-5 documentos mais similares à cada consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Compare os resultados encontrados e responda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Quais modelos você acha que trouxe os melhores resultados? Por que? Inspecione os documentos retornados para melhor embasar sua resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Calcule e reporte o overlap par-a-par entre os resultados de cada modelo (usando o índice de Jaccard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
