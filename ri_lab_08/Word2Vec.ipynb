{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando-se as dependências necessárias para a atividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import operator\n",
    "from gensim.models import Word2Vec\n",
    "from unicodedata import normalize\n",
    "from math import sqrt\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o modelo no gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'pt.bin.syn1neg.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bcd53d4cad3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodelo_pre_treinado_gesim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pt.bin'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pt.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\gensim\\models\\word2vec.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \"\"\"\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m             \u001b[1;31m# for backward compatibility for `max_final_vocab` feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\gensim\\models\\base_any2vec.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m         \"\"\"\n\u001b[1;32m-> 1244\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ns_exponent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mns_exponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\gensim\\models\\base_any2vec.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \"\"\"\n\u001b[1;32m--> 603\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\gensim\\utils.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\gensim\\utils.pyc\u001b[0m in \u001b[0;36m_load_specials\u001b[1;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[0;32m    467\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mignore_deprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'pt.bin.syn1neg.npy'"
     ]
    }
   ],
   "source": [
    "# Modelo com word-embeddings pré-treinados.\n",
    "modelo_pre_treinado_gesim = 'pt.bin'\n",
    "\n",
    "modelo = Word2Vec.load('pt.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo-se os títulos das notícias na coleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"results.csv\")\n",
    "titulos_colecao = data_frame[\"title\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares para o processamento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pontuacoes(texto):\n",
    "    '''\n",
    "        Remove-se as pontuações de um texto.\n",
    "    '''\n",
    "    return re.sub(r'[,.!?:*();#/&%]', '', str(texto))\n",
    "\n",
    "def remove_caracteres_numericos(texto):\n",
    "    '''\n",
    "        Remove-se os caracteres numéricos de um texto\n",
    "    '''\n",
    "    return re.sub(r'[0-9]', '', texto)\n",
    "    \n",
    "def remove_acentuacoes(texto):\n",
    "    '''\n",
    "        Remove as acentuações de um texto.\n",
    "    '''\n",
    "    texto_unicode = unicode(texto, \"utf-8\")\n",
    "    return normalize('NFKD', texto_unicode).encode('ASCII','ignore')\n",
    "\n",
    "def converte_letras_minusculas(texto):\n",
    "    '''\n",
    "        Transforma todas as letras do texto em minuscúlas.\n",
    "    '''\n",
    "    return texto.lower()\n",
    "\n",
    "def is_not_Vazio_ou_stop_word(token):\n",
    "    '''\n",
    "        Retorna um booleano indicando se o token é uma stop-word ou uma palavra vazia.\n",
    "    '''\n",
    "    stop_words = get_stop_words('pt')\n",
    "    \n",
    "    return (token not in stop_words) and token != ''\n",
    "    \n",
    "def remover_vazio_ou_stop_words(texto):\n",
    "    '''\n",
    "        Remove stop-words do texto, como: a, o, e, de, da, para, além de remover letras vazias\n",
    "    '''\n",
    "    lista_tokens = texto.split(\" \")\n",
    "    lista_token_sem_stop_words = filter(is_not_Vazio_ou_stop_word, lista_tokens)\n",
    "    \n",
    "    return \" \".join(lista_token_sem_stop_words)\n",
    "\n",
    "def formatar_texto_e_remover_stop_words(texto):\n",
    "    '''\n",
    "        Transforma o texto, eliminando acentuações, caracteres numéricos e pontuações, e\n",
    "        modificando todas as letras para  minúsculas. Além disso, remove stop-words do texto.\n",
    "    '''\n",
    "    \n",
    "    texto = remove_pontuacoes(texto)\n",
    "    texto = remove_caracteres_numericos(texto)\n",
    "    texto = remove_acentuacoes(texto)\n",
    "    texto = converte_letras_minusculas(texto)\n",
    "    texto = remover_vazio_ou_stop_words(texto)\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Implemente uma função que recebe uma notícia e retorna os vetores (word embeddings) das palavras do título dessa notícia a partir dos word embeddings pré-treinados com o gensim (30 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings_noticia(noticia):\n",
    "    '''\n",
    "        Obtém a lista de vetores (word embeddings) para cada palavra da noticia, e retorna um dicionário,\n",
    "        o qual se estrutura como: chave, a palavra da noticia, e valor, os vetores correspondentes a essa palavra.\n",
    "        Obs: se a palavra não se encontra no vocabulário, então a mesma será desconsiderada do word embedding.\n",
    "    '''\n",
    "    dic_vetores = {}\n",
    "    for palavra in noticia.split():\n",
    "        if(modelo.wv.__contains__(palavra)):\n",
    "            vetores = modelo.wv.__getitem__(palavra)\n",
    "            dic_vetores[palavra] = vetores\n",
    "        \n",
    "    return dic_vetores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Implemente uma função que calcula o WMD (Word Mover's Distance) entre duas notícias usando os embeddings das palavras dos respectivos títulos  (35 pts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinito = float(\"inf\")\n",
    "\n",
    "def calcular_wmd_manualmente(noticia_1, noticia_2):\n",
    "    '''\n",
    "        Calcula-se manualmente o WMD (Word Mover's Distance) entre as duas notícias passadas por parâmetro, ou seja,\n",
    "        a soma das distâncias minímas entre as palavras dessas notícias, e retorna esse valor. Para calcular, a mesma\n",
    "        precisa ter posse dos embeddings das palavras de cada notícia, os quais são obtidos na questão (1). Ademais, as\n",
    "        notícias precisam estar formatadas, ou seja, sem a presença de stop words, acentuações, espaços vazios, etc, para\n",
    "        proporcionar resultados mais precisos.\n",
    "    '''\n",
    "    # Obtém-se os embeddings das palavras.\n",
    "    dic_wv_noticia_1 = get_word_embeddings_noticia(noticia_1)\n",
    "    dic_wv_noticia_2 = get_word_embeddings_noticia(noticia_2)\n",
    "    \n",
    "    wmd = 0\n",
    "    for wv_noticia_1 in dic_wv_noticia_1.keys():\n",
    "        \n",
    "        # Define-se que até então a distância miníma entre a palavra da notícia_1 e as demais é infinito.\n",
    "        min_dist = infinito\n",
    "        for wv_noticia_2 in dic_wv_noticia_2.keys():\n",
    "            \n",
    "            # Obtém-se a menor distância entre os pontos das palavras da noticia_1 e noticia_2, considerando-se na\n",
    "            # comparação, a menor obtida até o presente momento e a distância entre as palavras atuais.\n",
    "            min_dist = min(min_dist, sqrt(sum((dic_wv_noticia_1[wv_noticia_1] - dic_wv_noticia_2[wv_noticia_2]) ** 2)))\n",
    "\n",
    "        # Adiciona-se a menor distância ao wmd para ter a soma total entre as palavras das duas notícias\n",
    "        wmd += min_dist * 1.0/len(dic_wv_noticia_1.keys())\n",
    "\n",
    "    return wmd\n",
    "    \n",
    "    \n",
    "def calcular_wmd(noticia_1, noticia_2):\n",
    "    '''\n",
    "        Calcula o WMD (Word Mover's Distance) entre as duas notícias passadas por parâmetro, ou seja, a soma\n",
    "        das distâncias minímas entre as palavras dessas notícias, e retorna esse valor. Para calcular, a mesma\n",
    "        precisa ter posse dos embeddings das palavras de cada notícia, os quais são obtidos na questão (1).\n",
    "        Para realizar o cálculo, as notícias são formatadas pela função formatar_texto_e_remover_stop_words, para\n",
    "        eliminar stop words, acentuações, espaços vazios, etc.\n",
    "        \n",
    "        OBS: Para o cálculo do wmd, utilizou-se a função wmdistance proporcionada pelo modelo do Word2Vec, não\n",
    "        obstante, pode-se calcular manualmente, implementando a função como é demonstrado na função\n",
    "        calcular_wmd_manualmente.\n",
    "    '''\n",
    "    noticia_1 = formatar_texto_e_remover_stop_words(noticia_1)\n",
    "    noticia_2 = formatar_texto_e_remover_stop_words(noticia_2)\n",
    "\n",
    "    wmd = modelo.wv.wmdistance(noticia_1,noticia_2)\n",
    "    \n",
    "    # Caso queira calcular manualmente, utiliza-se a função calcular_wmd_manualmente.\n",
    "    # wmd = calcular_wmd_manualmente(noticia_1,noticia_2)\n",
    "\n",
    "    return wmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Implemente uma função que possa receber qualquer notícia como entrada e retornar as top-3 notícias mais similares (menos distantes) a ela (35 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noticias_mais_similares(titulo_noticia):\n",
    "    '''\n",
    "        Obtém o título das 3 notícias mais similares ao título de titulo_noticia, considerando como as mais similares\n",
    "        as que possuem o menor WMD, ou seja menor distância, obtido pela função calular_wmd.\n",
    "    '''\n",
    "    # Tupla de dois índices, onde o primeiro índice é o título da notícia e o segundo índice é o wmd em relação ao titulo_noticia.\n",
    "    lista_tupla_noticia_similaridade = []\n",
    "    for titulo_noticia_comparada in titulos_colecao:\n",
    "        lista_tupla_noticia_similaridade.append((titulo_noticia_comparada,\n",
    "                                                 calcular_wmd(titulo_noticia, titulo_noticia_comparada)))\n",
    "    \n",
    "    # Ordena a lista de tuplas pelo menor wmd.\n",
    "    lista_tupla_noticia_similaridade.sort(key = operator.itemgetter(1))\n",
    "    # Obtém as 3 primeiras notícias, as quais são as mais similares.\n",
    "    tres_mais_similares = [titulo for titulo, peso in lista_tupla_noticia_similaridade[:3]]\n",
    "    \n",
    "    return tres_mais_similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise para uma consulta por \"governo do Brasil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Título</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bolsonaro (des)governa o Brasil pelo Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Governo Bolsonaro prega “negacionismo históric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Instruído por ministros  Bolsonaro dá sinal ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking                                             Título\n",
       "0        1       Bolsonaro (des)governa o Brasil pelo Twitter\n",
       "1        2  Governo Bolsonaro prega “negacionismo históric...\n",
       "2        3  Instruído por ministros  Bolsonaro dá sinal ve..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_governo_do_brasil = get_noticias_mais_similares(\"governo do Brasil\")\n",
    "\n",
    "colunas = [\"Ranking\", \"Título\"]\n",
    "tabela_resultado_governo_do_brasil = pd.DataFrame({\"Título\": resultado_governo_do_brasil,\n",
    "                                 \"Ranking\": xrange(1, 4)})\n",
    "tabela_resultado_governo_do_brasil = tabela_resultado_governo_do_brasil.reindex(columns=colunas)\n",
    "\n",
    "tabela_resultado_governo_do_brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe na tabela acima que todos títulos estão relacionados ao governo Bolsonaro que por conseguinte o atual governo do Brasil, os quais, apresentam pontos do governo. Logo, para essa pesquisa, o algoritmo funcionou como o esperado, retornando títulos similares ao esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise para uma consulta por \"tortura na ditadura\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Título</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>“Lógica de usar torturadores da ditadura no cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Na Argentina  falar da ditadura e dos militare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cúpula militar uruguaia cai após revelação de ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking                                             Título\n",
       "0        1  “Lógica de usar torturadores da ditadura no cr...\n",
       "1        2  Na Argentina  falar da ditadura e dos militare...\n",
       "2        3  Cúpula militar uruguaia cai após revelação de ..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_tortura_ditadura = get_noticias_mais_similares(\"tortura na ditadura\")\n",
    "\n",
    "colunas = [\"Ranking\", \"Título\"]\n",
    "tabela_resultado_tortura_ditadura = pd.DataFrame({\"Título\": resultado_tortura_ditadura,\n",
    "                                 \"Ranking\": xrange(1, 4)})\n",
    "tabela_resultado_tortura_ditadura = tabela_resultado_tortura_ditadura.reindex(columns=colunas)\n",
    "\n",
    "tabela_resultado_tortura_ditadura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe na tabela acima, são apresentados títulos referentes à ditadura e à tortura, como era o esperado. Isso novamente constata que o algoritmo está funcionando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise pela consulta \"Bolsonaro troca embaixada por escritório em Jerusalém  mas não evita retaliação palestina\", o qual é um título presente no conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Título</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bolsonaro troca embaixada por escritório em Je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Após acenar com embaixada  Bolsonaro anuncia e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rota mata 11 pessoas em Guararema  na terceira...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking                                             Título\n",
       "0        1  Bolsonaro troca embaixada por escritório em Je...\n",
       "1        2  Após acenar com embaixada  Bolsonaro anuncia e...\n",
       "2        3  Rota mata 11 pessoas em Guararema  na terceira..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_titulo_conjunto_dados = get_noticias_mais_similares(\n",
    "    \"Bolsonaro troca embaixada por escritório em Jerusalém  mas não evita retaliação palestina\")\n",
    "\n",
    "colunas = [\"Ranking\", \"Título\"]\n",
    "tabela_resultado_titulo_conjunto_dados = pd.DataFrame({\"Título\": resultado_titulo_conjunto_dados,\n",
    "                                 \"Ranking\": xrange(1, 4)})\n",
    "tabela_resultado_titulo_conjunto_dados = tabela_resultado_titulo_conjunto_dados.reindex(columns=colunas)\n",
    "\n",
    "tabela_resultado_titulo_conjunto_dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que o título considerado mais similar é o próprio título passado, além desse, o segundo também fala sobre a embaixada nem Jerusalém, enquanto que o terceiro pouco faz similaridade. Não obstante, ainda assim, o cálculo se apresenta funcional para buscar pela similaridade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
